{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio.Seq\n",
    "import random\n",
    "import logging\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from tral.paths import DATA_DIR, EXEC_DIR\n",
    "\n",
    "LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lina/.tral/data'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_type = 'DNA'\n",
    "sequence_type = 'AA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lina/.tral/data/Random/AA_human_3.txt\n"
     ]
    }
   ],
   "source": [
    "equilibrium_frequencies='human'\n",
    "file = os.path.join(DATA_DIR, 'Random', \"_\".join(\n",
    "                [sequence_type, equilibrium_frequencies, '3']) + '.txt')\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'r') as f:\n",
    "    a = f.readline()[:-1] # the [:-n] slices the \\n in the very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = 'AAA 27355  AAR 13526  AAN 5245'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [i.split(' ') for i in a.split('  ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = [tuple(i.split(' ')) for i in a.split('  ')]\n",
    "# could be done as tuple but not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.split('  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ACC', '1234961'],\n",
       " ['TAG', '1418129'],\n",
       " ['ACA', '2110825'],\n",
       " ['AAA', '3730381'],\n",
       " ['ATC', '1416077'],\n",
       " ['AAC', '1565899'],\n",
       " ['ATA', '2150297'],\n",
       " ['AGG', '2036293'],\n",
       " ['CCT', '2038987'],\n",
       " ['ACT', '1765957'],\n",
       " ['AGC', '1578913'],\n",
       " ['AAG', '2319992'],\n",
       " ['AGA', '2469764'],\n",
       " ['CAT', '1990437'],\n",
       " ['AAT', '2690682'],\n",
       " ['ATT', '2697364'],\n",
       " ['CTG', '2295041'],\n",
       " ['CTA', '1416668'],\n",
       " ['CTC', '1833177'],\n",
       " ['CAC', '1539479'],\n",
       " ['ACG', '274180'],\n",
       " ['CAA', '1974628'],\n",
       " ['AGT', '1766247'],\n",
       " ['CCA', '1970632'],\n",
       " ['CCG', '312550'],\n",
       " ['CCC', '1603710'],\n",
       " ['TAT', '2153460'],\n",
       " ['GGT', '1238326'],\n",
       " ['TGT', '2125245'],\n",
       " ['CGA', '224729'],\n",
       " ['CAG', '2287773'],\n",
       " ['CGC', '253492'],\n",
       " ['GAT', '1419183'],\n",
       " ['CGG', '313198'],\n",
       " ['CTT', '2327283'],\n",
       " ['TGC', '1588311'],\n",
       " ['GGG', '1605495'],\n",
       " ['GGA', '1779124'],\n",
       " ['TAA', '2326091'],\n",
       " ['GGC', '1305435'],\n",
       " ['TAC', '1209580'],\n",
       " ['TTC', '2278442'],\n",
       " ['TCG', '225261'],\n",
       " ['TTA', '2329234'],\n",
       " ['TTT', '3745135'],\n",
       " ['GAC', '1077061'],\n",
       " ['TCC', '1778916'],\n",
       " ['GAA', '2273427'],\n",
       " ['TCA', '2122834'],\n",
       " ['GCA', '1584257'],\n",
       " ['GTA', '1211199'],\n",
       " ['GCC', '1305322'],\n",
       " ['GTC', '1079586'],\n",
       " ['GCG', '253636'],\n",
       " ['GTG', '1546841'],\n",
       " ['GAG', '1833491'],\n",
       " ['GTT', '1573000'],\n",
       " ['GCT', '1583187'],\n",
       " ['TTG', '1987854'],\n",
       " ['CGT', '274425'],\n",
       " ['TGG', '1976609'],\n",
       " ['ATG', '1989762'],\n",
       " ['TCT', '2476525']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {i[0]: int(i[1]) for i in b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.unique(i[0] for i in frequencies.keys())\n",
    "\n",
    "# np.unique: find the unique elements of an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(i[0] for i in frequencies.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = np.unique([i[0] for i in frequencies.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sequence(n_samples, sequence_type='AA', return_type='repeat',\n",
    "                    equilibrium_frequencies='human', l=0, n=0,\n",
    "                    sequence_length=0):\n",
    "    \"\"\" Simulate random sequence locally.\n",
    "\n",
    "    Simulate random sequence locally.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int):  The number of samples\n",
    "        sequence_type (str): Either \"AA\" or \"DNA\"\n",
    "        return_type (str): Either \"repeat\" or \"list\"\n",
    "        equilibrium_frequencies (str): Only \"human\" option available at current\n",
    "        l (int): The length of the repeat unit\n",
    "        n (int): The number of repeat units in the tandem repeat\n",
    "        sequence_length (int): The total length of the simulated sequence\n",
    "\n",
    "    Returns:\n",
    "        Return type depends on ``return_type``.\n",
    "    \"\"\"\n",
    "\n",
    "    if sequence_length == 0 and (l == 0 or n == 0):\n",
    "        LOG.error('The specified sequence_length or the product of l and n was'\n",
    "                  ' set to 0 for random_sequence simulation')\n",
    "    else:\n",
    "        if sequence_length == 0:\n",
    "            sequence_length = l * n\n",
    "\n",
    "        if equilibrium_frequencies == 'human':\n",
    "            file = os.path.join(DATA_DIR, 'Random', \"_\".join(\n",
    "                [sequence_type, equilibrium_frequencies, '3']) + '.txt')\n",
    "\n",
    "        with open(file, 'r') as f:\n",
    "            a = f.readline()[:-1]\n",
    "        b = [i.split(' ') for i in a.split('  ')]\n",
    "        frequencies = {i[0]: int(i[1]) for i in b}\n",
    "        alphabet = np.unique([i[0] for i in frequencies.keys()]) #inclusion of []\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            seed_int = random.randint(1, sum(frequencies.values()))\n",
    "            for key, value in frequencies.items():\n",
    "                seed_int -= value\n",
    "                if seed_int <= 0:\n",
    "                    seed = key\n",
    "                    break\n",
    "\n",
    "            dimer = [''.join(i) for i in itertools.product(alphabet, repeat=2)]\n",
    "            third_letter_frequencies = {\n",
    "                iD: {\n",
    "                    iA: frequencies[\n",
    "                        iD +\n",
    "                        iA] for iA in alphabet} for iD in dimer}\n",
    "\n",
    "            sequence = seed\n",
    "            for _ in range(sequence_length - 3):\n",
    "                next_int = random.randint(\n",
    "                    1, sum(third_letter_frequencies[sequence[-2:]].values()))\n",
    "                for key, value in third_letter_frequencies[\n",
    "                        sequence[-2:]].items():\n",
    "                    next_int -= value\n",
    "                    if next_int <= 0:\n",
    "                        sequence += key\n",
    "                        break\n",
    "\n",
    "            # return Repeat instances\n",
    "            if return_type == 'repeat' and not l == 0 and not n == 0:\n",
    "                yield [sequence[i * l:(i + 1) * l] for i in range(n)], sequence_type\n",
    "            elif return_type == 'list':\n",
    "                yield sequence\n",
    "            else:  # return seqIO instances\n",
    "                yield Bio.Seq.Seq(sequence, sequence_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(1, sum(frequencies.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for one sample\n",
    "seed_int = random.randint(1, sum(frequencies.values()))\n",
    "for key, value in frequencies.items():\n",
    "    seed_int -= value\n",
    "    print(\"seed_int\",seed_int)\n",
    "    print(\"seed\",seed)\n",
    "    if seed_int <= 0:\n",
    "        print(seed)\n",
    "        seed = key\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#product('ABCD', repeat=2)\n",
    "#AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD\n",
    "dimer = [''.join(i) for i in itertools.product(alphabet, repeat=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = itertools.product(alphabet, repeat=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_letter_frequencies = {\n",
    "    iD: {\n",
    "        iA: frequencies[\n",
    "            iD +\n",
    "            iA] for iA in alphabet} for iD in dimer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_list = random_sequence(2, sequence_type='DNA', return_type='list',equilibrium_frequencies='human', l=100, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_repeat = random_sequence(3, sequence_type='AA', return_type='repeat',equilibrium_frequencies='human', l=1000, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_else = random_sequence(3, sequence_type='AA', return_type='else',equilibrium_frequencies='human', l=10, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_seq_else) # gives Bio.Seq.Seq(sequence, sequence_type)\n",
    "for i in test_seq_list:\n",
    "    print(\"i\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object random_sequence at 0x7f02cebadb10>\n",
      "i AAAAGCTTAAACAGCTGCAAGTGGCCTGGCAAGGAGAAGAGCTTTTTTCAGGTTTACCAGCTTTTAGCCCAAGAGTGCAGAGAGCATCTCACTCTTTCAG\n",
      "i ATTTTGGACCAACAAGTGACCACCATCCTCGCATCTGCTTTCGATTCAGTCAAAGCCTTAAATACATTATCCACAGCCGTTCGTAACAGTGTATGACGAA\n"
     ]
    }
   ],
   "source": [
    "print(test_seq_list)\n",
    "for i in test_seq_list:\n",
    "    print(\"i\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_seq_repeat)\n",
    "for i in test_seq_repeat:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(i) for i in test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "runfile_template = os.path.join(DATA_DIR, \"ALF\", \"template.drw\")\n",
    "alf_exec = os.path.join(EXEC_DIR, \"alfsim\")\n",
    "# create temporary directory\n",
    "working_dir = tempfile.mkdtemp()\n",
    "LOG.debug(\"evolvedTR: Created tempfile: %s\", working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lina/.tral/data/ALF/template.drw'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runfile_template \n",
    "# manually created directory /home/lina/.tral/data/ALF and put alf-params.drw into it\n",
    "# named as template.drw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/bin/alfsim'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alf_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp2cb8pzx6/alf.drw'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create working dir\n",
    "if not os.path.isdir(working_dir):\n",
    "    os.makedirs(working_dir)\n",
    "\n",
    "# Copy template file and append job specific info\n",
    "runfilename = \"alf.drw\"\n",
    "shutil.copyfile(runfile_template, os.path.join(working_dir, runfilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if indel_rate_per site:\n",
    "\n",
    "indel_rate_per_site = 3\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# insertion rate per site and PAM. E.g. for PAM=40 expect\n",
    "# aaGainRate*40 insertions per site.\n",
    "with open(os.path.join(working_dir, runfilename), \"a\") as runfile:\n",
    "    runfile.write(\n",
    "        \"aaGainRate := \" + str(indel_rate_per_site / mutation_rate) + \";\\n\")\n",
    "    runfile.write(\n",
    "        \"aaLossRate := \" + str(indel_rate_per_site / mutation_rate) + \";\\n\")\n",
    "    runfile.write(\"maxIndelLength := 50;\\n\")\n",
    "    runfile.write(\"indelModel := 'ZIPF';\\n\")\n",
    "    runfile.write(\"Z_c := 1.821;\\n\")\n",
    "    runfile.write(\"DawgPlacement := true;\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"test_id_name\"\n",
    "n_samples = 2\n",
    "n = 3\n",
    "l = 8\n",
    "\n",
    "with open(os.path.join(working_dir, runfilename), \"a\") as runfile:\n",
    "    runfile.write(\"uuid := '\" + job_id + \"';\\n\")\n",
    "    runfile.write(\"mname := '\" + job_id + \"';\\n\")\n",
    "    runfile.write(\"protStart := \" + str(n_samples) + \";\\n\")\n",
    "    runfile.write(\"NSpecies := \" + str(n) + \";\\n\")\n",
    "    runfile.write(\"minGeneLength := \" + str(l) + \";\\n\")\n",
    "    runfile.write(\"mutRate := \" + str(mutation_rate) + \";\\n\")\n",
    "    runfile.write(\"wdir := '\" + working_dir + \"';\\n\")\n",
    "\n",
    "tree_length = n * mutation_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters concerning the species tree\n",
    "#if tree == 'star':\n",
    "# BDTree, ToLSample, Custom\n",
    "with open(os.path.join(working_dir, runfilename), \"a\") as runfile:\n",
    "    runfile.write(\"treeType := 'Custom':\\n\")\n",
    "    runfile.write(\n",
    "        \"tree := MakeStarTree(BirthDeathTree(0.1,0.1,\" + str(n) + \",10),mutRate):\\n\")\n",
    "    runfile.write(\"treeLength:= %d ;\\n\" % tree_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BDTree, ToLSample, Custom\n",
    "\n",
    "#else\n",
    "runfile.write(\"treeType := 'BDTree':\\n\")\n",
    "# From the last discussion with Daniel, only the ration of birth to\n",
    "# death rate matters, if we scale tree to match pam distance\n",
    "runfile.write(\"birthRate := 0.01:\\n\")\n",
    "runfile.write(\"deathRate := 0.01:\\n\")\n",
    "# for BDTree: should resulting tree be ultrametric, e.g. all leaves\n",
    "# have same distance to origin?\n",
    "runfile.write(\"ultrametric := false:\\n\")\n",
    "runfile.write(\"treeLength:= %d ;\\n\" % tree_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/tmp/tmp2cb8pzx6/alf.drw' mode='a' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "print(runfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TRs = evolved_tandem_repeats(10, 3, 1, \"AA\", job_id='test',\n",
    "                           mutation_rate=50, tree='birthdeath',\n",
    "                           indel_rate_per_site=False,\n",
    "                           return_type='repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TRs = evolved_tandem_repeats(10, 3, 2, \"DNA\", job_id='test',\n",
    "                           mutation_rate=50, tree='birthdeath',\n",
    "                           indel_rate_per_site=False,\n",
    "                           return_type='repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALFSIM was not able to produce simulated sequence.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmpj5a0dwql/test/MSA/MSA_all_dna.phy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-84cc787b20c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_TRs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-a1ad8cb8a17b>\u001b[0m in \u001b[0;36mevolved_tandem_repeats\u001b[0;34m(l, n, n_samples, sequence_type, job_id, mutation_rate, tree, indel_rate_per_site, return_type)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mLOG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Line %d: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmpj5a0dwql/test/MSA/MSA_all_dna.phy'"
     ]
    }
   ],
   "source": [
    "for i in test_TRs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolved_tandem_repeats(l, n, n_samples, sequence_type, job_id='job_id',\n",
    "                           mutation_rate=50, tree='star',\n",
    "                           indel_rate_per_site=False,\n",
    "                           return_type='repeat'):\n",
    "    \"\"\" Simulate evolved sequences with ALF.\n",
    "\n",
    "    Simulate evolved sequences with ALF:\n",
    "    Dalquen, D. A., Anisimova, M., Gonnet, G. H. & Dessimoz, C.\n",
    "    ALF--a simulation framework for genome evolution. Molecular Biology and Evolution 29,\n",
    "    1115â€“1123 (2012).\n",
    "\n",
    "    Args:\n",
    "        l (int): The length of the repeat unit\n",
    "        n (int): The number of repeat units in the tandem repeat\n",
    "        n_samples (int):  The number of samples\n",
    "        sequence_type (str): Either \"AA\" or \"DNA\"\n",
    "        job_id (str): A tag for files produces with ALF, and result files.\n",
    "        mutation_rate (float): The mutation rate.\n",
    "        tree (str): The type of tree, e.g. \"star\" or \"birthdeath\"\n",
    "        indel_rate_per_site (int or False): The indel rate per site.\n",
    "        return_type (str): Either \"repeat\" or \"list\"\n",
    "\n",
    "        sequence_length (int): The total length of the simulated sequence\n",
    "\n",
    "    Returns:\n",
    "        Return type depends on ``return_type``: ``Repeat`` or ``Bio.Seq.Seq`` instance.\n",
    "    \"\"\"\n",
    "\n",
    "    runfile_template = os.path.join(DATA_DIR, \"ALF\", \"template.drw\")\n",
    "    alf_exec = os.path.join(EXEC_DIR, \"alfsim\")\n",
    "    # create temporary directory\n",
    "    working_dir = tempfile.mkdtemp()\n",
    "    LOG.debug(\"evolvedTR: Created tempfile: %s\", working_dir)\n",
    "\n",
    "    # create working dir\n",
    "    if not os.path.isdir(working_dir):\n",
    "        os.makedirs(working_dir)\n",
    "\n",
    "    # Copy template file and append job specific info\n",
    "    runfilename = \"alf.drw\"\n",
    "    shutil.copyfile(runfile_template, os.path.join(working_dir, runfilename))\n",
    "\n",
    "    with open(os.path.join(working_dir, runfilename), \"a\") as runfile:\n",
    "        if indel_rate_per_site:\n",
    "            # insertion rate per site and PAM. E.g. for PAM=40 expect\n",
    "            # aaGainRate*40 insertions per site.\n",
    "            runfile.write(\n",
    "                \"aaGainRate := \" + str(indel_rate_per_site / mutation_rate) + \";\\n\")\n",
    "            runfile.write(\n",
    "                \"aaLossRate := \" + str(indel_rate_per_site / mutation_rate) + \";\\n\")\n",
    "            runfile.write(\"maxIndelLength := 50;\\n\")\n",
    "            runfile.write(\"indelModel := 'ZIPF';\\n\")\n",
    "            runfile.write(\"Z_c := 1.821;\\n\")\n",
    "            runfile.write(\"DawgPlacement := true;\\n\")\n",
    "        runfile.write(\"uuid := '\" + job_id + \"';\\n\")\n",
    "        runfile.write(\"mname := '\" + job_id + \"';\\n\")\n",
    "        runfile.write(\"protStart := \" + str(n_samples) + \";\\n\")\n",
    "        runfile.write(\"NSpecies := \" + str(n) + \";\\n\")\n",
    "        runfile.write(\"minGeneLength := \" + str(l) + \";\\n\")\n",
    "        runfile.write(\"mutRate := \" + str(mutation_rate) + \";\\n\")\n",
    "        runfile.write(\"wdir := '\" + working_dir + \"';\\n\")\n",
    "\n",
    "        tree_length = n * mutation_rate\n",
    "        # parameters concerning the species tree\n",
    "        if tree == 'star':\n",
    "            # BDTree, ToLSample, Custom\n",
    "            runfile.write(\"treeType := 'Custom':\\n\")\n",
    "            runfile.write(\n",
    "                \"tree := MakeStarTree(BirthDeathTree(0.1,0.1,\" + str(n) + \",10),mutRate):\\n\")\n",
    "            runfile.write(\"treeLength:= %d ;\\n\" % tree_length)\n",
    "        else:\n",
    "            # BDTree, ToLSample, Custom\n",
    "            runfile.write(\"treeType := 'BDTree':\\n\")\n",
    "            # From the last discussion with Daniel, only the ration of birth to\n",
    "            # death rate matters, if we scale tree to match pam distance\n",
    "            runfile.write(\"birthRate := 0.01:\\n\")\n",
    "            runfile.write(\"deathRate := 0.01:\\n\")\n",
    "            # for BDTree: should resulting tree be ultrametric, e.g. all leaves\n",
    "            # have same distance to origin?\n",
    "            runfile.write(\"ultrametric := false:\\n\")\n",
    "            runfile.write(\"treeLength:= %d ;\\n\" % tree_length)\n",
    "            # DANIEL: Is a tree := missing?\n",
    "        if tree not in {'star', 'birthdeath'}:\n",
    "            LOG.warning(\n",
    "                \"evolvedTR: tree input %s not known, assuming birthdeath tree\",\n",
    "                tree)\n",
    "\n",
    "        # parameters concerning the substitution models\n",
    "        if sequence_type == 'AA':\n",
    "            runfile.write(\n",
    "                \"substModels := [SubstitutionModel('CustomP', ['\" +\n",
    "                os.path.join(\n",
    "                    DATA_DIR,\n",
    "                    'ALF',\n",
    "                    'lg.dat') +\n",
    "                \"'])];\\n\")\n",
    "            # CHECK! DOES\n",
    "            # substModels := [SubstitutionModel('LG')];\n",
    "            # WORK?\n",
    "        elif sequence_type == 'DNA':\n",
    "            runfile.write(\n",
    "                \"substModels := [SubstitutionModel('TN93', [.3, .4, .7],[seq(0.25,4)], true)]:\\n\")\n",
    "            # CHECK! DO THE EMPIRICAL PARAMETERS MAKE SENSE AT ALL?\n",
    "            # compare to http://people.inf.ethz.ch/ddalquen/alf/ALF_manual.pdf\n",
    "        else:  # CODONS\n",
    "            runfile.write(\"substModels := [SubstitutionModel('CPAM')];\\n\")\n",
    "\n",
    "    # Determine ALF MSA output file path\n",
    "    if sequence_type == 'AA':\n",
    "        infile = os.path.join(working_dir, job_id, \"MSA\", \"MSA_all_aa.phy\")\n",
    "    elif sequence_type == 'DNA':\n",
    "        infile = os.path.join(working_dir, job_id, \"MSA\", \"MSA_all_dna.phy\")\n",
    "    else:  # CODONS\n",
    "        infile = os.path.join(\n",
    "            working_dir,\n",
    "            job_id,\n",
    "            \"MSA\",\n",
    "            \"MSA_all_codon.phy\")\n",
    "\n",
    "    for i in range(10):\n",
    "        with open(os.path.join(working_dir, \"out.txt\"), \"w\") as outfile:\n",
    "            alf_process = subprocess.Popen([alf_exec,\n",
    "                                            runfilename],\n",
    "                                           cwd=working_dir,\n",
    "                                           stdout=outfile,\n",
    "                                           stderr=outfile,\n",
    "                                           close_fds=True)\n",
    "            alf_process.wait()\n",
    "        if os.path.isfile(infile):\n",
    "            break\n",
    "    else:\n",
    "        LOG.error('ALFSIM was not able to produce simulated sequence.')\n",
    "\n",
    "    # shutil.rmtree('/cluster/home/infk/eschaper/spielwiese/')\n",
    "    #shutil.copytree(working_dir, '/cluster/home/infk/eschaper/spielwiese/')\n",
    "\n",
    "    \"\"\" Read in MSA data from ALF\n",
    "        The following is a short parser for ALFsim output files\n",
    "        yielding MSAs as lists of strings,\n",
    "        based on a special flavour of  Felstein stein MSA files \"\"\"\n",
    "\n",
    "    # find a repeat uni\n",
    "    pattern_start = re.compile(\"\\d+ \\d+\")\n",
    "    pattern_seq = re.compile(\"\\S+[ ]+([A-Z\\-]+)\")\n",
    "\n",
    "    # Our possible parser states:\n",
    "    #\n",
    "    # state 1: Find beginning of MSA (Felsenstein)\n",
    "    # state 2: Find all repeat units\n",
    "\n",
    "    # protein ::=\n",
    "    #    \\d \\d\n",
    "    #    \\S/\\S    repeatunits\n",
    "    #\n",
    "\n",
    "    state = 1\n",
    "    with open(infile, \"r\") as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            LOG.debug(\"Line %d: %s\", i, line[0:-1])\n",
    "\n",
    "            if 1 == state:  # Find first repeat unit & save begin\n",
    "                search = pattern_start.search(line)\n",
    "                if search:\n",
    "                    LOG.debug(\" *(1->2) Found MSA start\")\n",
    "                    state = 2\n",
    "                    msa = []\n",
    "\n",
    "            elif 2 == state:  # Find all repeat units\n",
    "                search = pattern_seq.search(line)\n",
    "                if search:\n",
    "                    LOG.debug(\" *(2->2) Found another repeat unit\")\n",
    "                    msa.append(search.group(1))\n",
    "                else:\n",
    "                    LOG.debug(\" *(2->1) repeat region finished, yielding.\")\n",
    "                    state = 1\n",
    "                    # YIELD IF WE HAVE FOUND AT LEAST TWO REPEAT UNITS:\n",
    "                    if len(msa) > 1:\n",
    "                        if return_type == 'repeat':\n",
    "                            yield repeat.Repeat(begin=0, msa=msa, sequence_type=sequence_type)\n",
    "                        elif return_type == 'list':\n",
    "                            yield msa\n",
    "                        else:\n",
    "                            LOG.debug(\"YIELD: %s\",\n",
    "                                      \"\".join(msa).replace('-', ''))\n",
    "                            yield Bio.Seq.Seq(\"\".join(msa).replace('-', ''), sequence_type)\n",
    "\n",
    "    # delete temporary directory\n",
    "    try:\n",
    "        shutil.rmtree(working_dir)\n",
    "    except OSError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test directly in bash:\n",
    "# alfsim /tmp/tmp0h0w116y/alf.drw stdout=/tmp/tmp0h0w116y/out.txt stderr=/tmp/tmp0h0w116y/out.txt close_fds=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/bin/alfsim'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alf_exec # = alfsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "runfile = os.path.join(working_dir,runfilename)\n",
    "outfile = os.path.join(working_dir, \"out.txt\") \n",
    "infile = os.path.join(working_dir, job_id, \"MSA\", \"MSA_all_aa.phy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp0h0w116y/alf.drw\n",
      "/tmp/tmp0h0w116y/test_id_name/MSA/MSA_all_aa.phy\n",
      "/tmp/tmp0h0w116y/out.txt\n"
     ]
    }
   ],
   "source": [
    "print(runfile)\n",
    "print(outfile)\n",
    "print(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(seq_filename, sequence_type='AA'):\n",
    "    \"\"\" Read repeat from file in fasta format.\n",
    "\n",
    "    Read repeat from file in fasta format.\n",
    "\n",
    "    Args:\n",
    "        seq_filename (str):  Path to the repeats containing fasta file\n",
    "        sequence_type (str): Either \"AA\" or \"DNA\"\n",
    "\n",
    "    Returns:\n",
    "        (list of Repeat): A list of Repeat instances.\n",
    "    \"\"\"\n",
    "\n",
    "    pat_start = re.compile(r\">(.*)\")\n",
    "    pat_repeat_unit = re.compile(r\"([\\w\\.\\-]+)\")\n",
    "\n",
    "    # Our possible parser states:\n",
    "    #\n",
    "    # 1: searching for sequence name\n",
    "    # 2: searching for repeat units\n",
    "\n",
    "    repeats = {}\n",
    "    state = 1\n",
    "    with open(seq_filename, \"rt\") as infile:\n",
    "\n",
    "        for i, line in enumerate(infile):\n",
    "            LOG.debug(\"Line {0}: {1}\".format(i, line[0:-1]))\n",
    "            if 1 == state:\n",
    "                match = pat_start.match(line)\n",
    "                if match:\n",
    "                    LOG.debug(\" * (1->2) Found start\")\n",
    "                    LOG.debug(\"Start: %s\", match.group(1))\n",
    "                    name = match.group(1)\n",
    "                    repeats[name] = []\n",
    "                    state = 2\n",
    "\n",
    "            elif 2 == state:\n",
    "                match = pat_repeat_unit.match(line)\n",
    "                if match:\n",
    "                    LOG.debug(\" * (2->2) Found Repeat unit\")\n",
    "                    LOG.debug(\"Repeat Unit: %s\", match.group(1))\n",
    "                    repeat_unit = match.group(1)\n",
    "                    repeats[name].append(repeat_unit.replace(\".\", \"-\").upper())\n",
    "                else:\n",
    "                    LOG.debug(\" * (2->1) Found NO further Repeat unit\")\n",
    "                    state = 1\n",
    "\n",
    "    for i_name, iR in repeats.items():\n",
    "        yield iR, sequence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_repeat_fasta(tandem_repeats, file):\n",
    "    \"\"\" save multiple <tandem_repeats> in Fasta format in specified <file>\n",
    "\n",
    "        At current, only one TR per sequence can be defined, as the identifiers\n",
    "        in the dict <tandem_repeats> must be unique.\n",
    "\n",
    "        Parameters: Dict of tandem repeats and identifiers.\n",
    "            e.g. {'ENSP00012': msa1, 'ENSP00013': msa2}\n",
    "\n",
    "            >ID\n",
    "            GHKI\n",
    "            GHKI\n",
    "            GH--\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file, 'w', newline='\\n') as f:\n",
    "        for identifier, msa in tandem_repeats.items():\n",
    "            f.write(\">{0}\\n\".format(identifier))\n",
    "            f.write(\"\\n\".join(msa) + \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
